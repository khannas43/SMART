{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Auto Identification of Beneficiaries - Fairness Audit\n",
        "\n",
        "**Use Case:** AI-PLATFORM-03 - Auto Identification of Beneficiaries  \n",
        "**Objective:** Audit eligibility identification for demographic fairness and bias detection  \n",
        "**MLflow Experiment:** `smart/identification_beneficiary/*`\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook performs fairness audits on:\n",
        "- Eligibility rates by demographic groups (caste, gender, geography)\n",
        "- ML score distributions across protected attributes\n",
        "- Rule engine bias detection\n",
        "- Hybrid evaluator fairness metrics\n",
        "- Geographic coverage equity\n",
        "- Scheme-wise fairness analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yaml\n",
        "import warnings\n",
        "from scipy import stats\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add paths\n",
        "project_root = Path().absolute().parent.parent.parent.parent\n",
        "sys.path.append(str(project_root / 'shared' / 'utils'))\n",
        "from db_connector import DBConnector\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 7)\n",
        "\n",
        "# Load config\n",
        "config_path = Path().absolute().parent.parent / \"config\" / \"db_config.yaml\"\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Connect to database\n",
        "db = DBConnector(\n",
        "    host=config['database']['host'],\n",
        "    port=config['database']['port'],\n",
        "    database=config['database']['name'],\n",
        "    user=config['database']['user'],\n",
        "    password=config['database']['password']\n",
        ")\n",
        "db.connect()\n",
        "\n",
        "print(\"‚úÖ Connected to database\")\n",
        "print(f\"   Database: {config['database']['name']} at {config['database']['host']}:{config['database']['port']}\")\n",
        "print(f\"   Schema: {config['database']['schema']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Demographic Fairness Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze eligibility by demographic groups (combining with Golden Records if available)\n",
        "try:\n",
        "    # First, try to get data from eligibility snapshots joined with golden records\n",
        "    fairness_query = \"\"\"\n",
        "    SELECT \n",
        "        CASE \n",
        "            WHEN gr.caste_id = 1 THEN 'GEN'\n",
        "            WHEN gr.caste_id = 2 THEN 'OBC'\n",
        "            WHEN gr.caste_id = 3 THEN 'SC'\n",
        "            WHEN gr.caste_id = 4 THEN 'ST'\n",
        "            ELSE 'OTHER'\n",
        "        END as caste_group,\n",
        "        CASE \n",
        "            WHEN gr.gender = 'M' THEN 'Male'\n",
        "            WHEN gr.gender = 'F' THEN 'Female'\n",
        "            ELSE 'Other'\n",
        "        END as gender_group,\n",
        "        es.scheme_code,\n",
        "        COUNT(*) as total_candidates,\n",
        "        COUNT(*) FILTER (WHERE es.rule_status = 'ELIGIBLE') as eligible_count,\n",
        "        COUNT(*) FILTER (WHERE es.rule_status = 'NOT_ELIGIBLE') as not_eligible_count,\n",
        "        AVG(es.ml_score) as avg_ml_score,\n",
        "        AVG(es.hybrid_score) as avg_hybrid_score\n",
        "    FROM eligibility.eligibility_snapshots es\n",
        "    LEFT JOIN golden_record.golden_records gr ON es.beneficiary_id = gr.gr_id\n",
        "    WHERE gr.caste_id IS NOT NULL\n",
        "    GROUP BY caste_group, gender_group, es.scheme_code\n",
        "    ORDER BY total_candidates DESC\n",
        "    LIMIT 100\n",
        "    \"\"\"\n",
        "    fairness_df = pd.read_sql(fairness_query, db.connection)\n",
        "    \n",
        "    if len(fairness_df) > 0:\n",
        "        print(\"üìä Demographic Fairness Analysis:\")\n",
        "        print(f\"   Found {len(fairness_df)} demographic-group-scheme combinations\")\n",
        "        \n",
        "        # Calculate eligibility rates\n",
        "        fairness_df['eligibility_rate'] = fairness_df['eligible_count'] / fairness_df['total_candidates']\n",
        "        \n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        \n",
        "        # Eligibility rate by caste\n",
        "        caste_eligibility = fairness_df.groupby('caste_group').agg({\n",
        "            'eligible_count': 'sum',\n",
        "            'total_candidates': 'sum'\n",
        "        })\n",
        "        caste_eligibility['eligibility_rate'] = caste_eligibility['eligible_count'] / caste_eligibility['total_candidates']\n",
        "        axes[0, 0].bar(caste_eligibility.index, caste_eligibility['eligibility_rate'].values, \n",
        "                      color=['blue', 'green', 'orange', 'red', 'purple'], alpha=0.7)\n",
        "        axes[0, 0].set_title('Eligibility Rate by Caste Group')\n",
        "        axes[0, 0].set_ylabel('Eligibility Rate')\n",
        "        axes[0, 0].set_ylim(0, 1)\n",
        "        \n",
        "        # Eligibility rate by gender\n",
        "        gender_eligibility = fairness_df.groupby('gender_group').agg({\n",
        "            'eligible_count': 'sum',\n",
        "            'total_candidates': 'sum'\n",
        "        })\n",
        "        gender_eligibility['eligibility_rate'] = gender_eligibility['eligible_count'] / gender_eligibility['total_candidates']\n",
        "        axes[0, 1].bar(gender_eligibility.index, gender_eligibility['eligibility_rate'].values, \n",
        "                      color=['blue', 'pink', 'gray'], alpha=0.7)\n",
        "        axes[0, 1].set_title('Eligibility Rate by Gender')\n",
        "        axes[0, 1].set_ylabel('Eligibility Rate')\n",
        "        axes[0, 1].set_ylim(0, 1)\n",
        "        \n",
        "        # ML Score distribution by caste\n",
        "        caste_scores = fairness_df.groupby('caste_group')['avg_ml_score'].mean()\n",
        "        axes[1, 0].bar(caste_scores.index, caste_scores.values, \n",
        "                      color=['blue', 'green', 'orange', 'red', 'purple'], alpha=0.7)\n",
        "        axes[1, 0].set_title('Average ML Score by Caste Group')\n",
        "        axes[1, 0].set_ylabel('Average ML Score')\n",
        "        \n",
        "        # Hybrid Score distribution by caste\n",
        "        caste_hybrid = fairness_df.groupby('caste_group')['avg_hybrid_score'].mean()\n",
        "        axes[1, 1].bar(caste_hybrid.index, caste_hybrid.values, \n",
        "                      color=['blue', 'green', 'orange', 'red', 'purple'], alpha=0.7)\n",
        "        axes[1, 1].set_title('Average Hybrid Score by Caste Group')\n",
        "        axes[1, 1].set_ylabel('Average Hybrid Score')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Statistical tests for fairness\n",
        "        print(\"\\nüìà Statistical Fairness Tests:\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        # Chi-square test for independence (caste vs eligibility)\n",
        "        contingency_caste = pd.crosstab(\n",
        "            fairness_df['caste_group'], \n",
        "            (fairness_df['eligible_count'] > fairness_df['not_eligible_count'])\n",
        "        )\n",
        "        chi2_caste, p_value_caste, dof_caste, expected_caste = stats.chi2_contingency(contingency_caste)\n",
        "        print(f\"\\nCaste vs Eligibility (Chi-square test):\")\n",
        "        print(f\"   Chi-square statistic: {chi2_caste:.4f}\")\n",
        "        print(f\"   P-value: {p_value_caste:.4f}\")\n",
        "        print(f\"   {'‚ö†Ô∏è Significant bias detected' if p_value_caste < 0.05 else '‚úÖ No significant bias detected'} (Œ±=0.05)\")\n",
        "        \n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No demographic fairness data found.\")\n",
        "        print(\"   This may require joining with Golden Records data.\")\n",
        "        print(\"   Ensure eligibility snapshots have beneficiary_id linking to golden_records.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Demographic fairness analysis error: {e}\")\n",
        "    print(\"   This is expected if eligibility snapshots haven't been created yet or\")\n",
        "    print(\"   if the data structure doesn't include demographic information.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Geographic Equity Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze geographic equity\n",
        "try:\n",
        "    geo_fairness_query = \"\"\"\n",
        "    SELECT \n",
        "        district_id,\n",
        "        COUNT(*) as total_candidates,\n",
        "        COUNT(*) FILTER (WHERE rule_status = 'ELIGIBLE') as eligible_count,\n",
        "        AVG(hybrid_score) as avg_hybrid_score,\n",
        "        STDDEV(hybrid_score) as std_hybrid_score\n",
        "    FROM eligibility.eligibility_snapshots\n",
        "    WHERE district_id IS NOT NULL\n",
        "    GROUP BY district_id\n",
        "    HAVING COUNT(*) >= 10\n",
        "    ORDER BY total_candidates DESC\n",
        "    \"\"\"\n",
        "    geo_fairness_df = pd.read_sql(geo_fairness_query, db.connection)\n",
        "    \n",
        "    if len(geo_fairness_df) > 0:\n",
        "        geo_fairness_df['eligibility_rate'] = geo_fairness_df['eligible_count'] / geo_fairness_df['total_candidates']\n",
        "        \n",
        "        print(f\"üó∫Ô∏è Geographic Equity Analysis ({len(geo_fairness_df)} districts):\")\n",
        "        print(f\"   Average Eligibility Rate: {geo_fairness_df['eligibility_rate'].mean():.3f}\")\n",
        "        print(f\"   Std Dev of Eligibility Rate: {geo_fairness_df['eligibility_rate'].std():.3f}\")\n",
        "        print(f\"   Coefficient of Variation: {geo_fairness_df['eligibility_rate'].std() / geo_fairness_df['eligibility_rate'].mean():.3f}\")\n",
        "        \n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        \n",
        "        # Eligibility rate distribution\n",
        "        axes[0, 0].hist(geo_fairness_df['eligibility_rate'], bins=20, edgecolor='black', alpha=0.7)\n",
        "        axes[0, 0].axvline(geo_fairness_df['eligibility_rate'].mean(), color='red', linestyle='--', \n",
        "                          label=f'Mean: {geo_fairness_df[\"eligibility_rate\"].mean():.3f}')\n",
        "        axes[0, 0].set_title('Eligibility Rate Distribution by District')\n",
        "        axes[0, 0].set_xlabel('Eligibility Rate')\n",
        "        axes[0, 0].set_ylabel('Number of Districts')\n",
        "        axes[0, 0].legend()\n",
        "        \n",
        "        # Top and bottom districts\n",
        "        top_districts = geo_fairness_df.nlargest(10, 'eligibility_rate')\n",
        "        bottom_districts = geo_fairness_df.nsmallest(10, 'eligibility_rate')\n",
        "        \n",
        "        axes[0, 1].barh(range(len(top_districts)), top_districts['eligibility_rate'].values, \n",
        "                       alpha=0.7, color='green', label='Top 10')\n",
        "        axes[0, 1].set_yticks(range(len(top_districts)))\n",
        "        axes[0, 1].set_yticklabels(top_districts['district_id'])\n",
        "        axes[0, 1].set_title('Top 10 Districts by Eligibility Rate')\n",
        "        axes[0, 1].set_xlabel('Eligibility Rate')\n",
        "        \n",
        "        axes[1, 0].barh(range(len(bottom_districts)), bottom_districts['eligibility_rate'].values, \n",
        "                       alpha=0.7, color='red', label='Bottom 10')\n",
        "        axes[1, 0].set_yticks(range(len(bottom_districts)))\n",
        "        axes[1, 0].set_yticklabels(bottom_districts['district_id'])\n",
        "        axes[1, 0].set_title('Bottom 10 Districts by Eligibility Rate')\n",
        "        axes[1, 0].set_xlabel('Eligibility Rate')\n",
        "        \n",
        "        # Scatter: candidates vs eligibility rate\n",
        "        axes[1, 1].scatter(geo_fairness_df['total_candidates'], geo_fairness_df['eligibility_rate'], \n",
        "                          alpha=0.6, s=100)\n",
        "        axes[1, 1].set_title('Candidate Count vs Eligibility Rate by District')\n",
        "        axes[1, 1].set_xlabel('Total Candidates')\n",
        "        axes[1, 1].set_ylabel('Eligibility Rate')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Identify equity gaps\n",
        "        equity_gap = geo_fairness_df['eligibility_rate'].max() - geo_fairness_df['eligibility_rate'].min()\n",
        "        print(f\"\\n‚ö†Ô∏è Equity Gap Analysis:\")\n",
        "        print(f\"   Maximum Eligibility Rate: {geo_fairness_df['eligibility_rate'].max():.3f}\")\n",
        "        print(f\"   Minimum Eligibility Rate: {geo_fairness_df['eligibility_rate'].min():.3f}\")\n",
        "        print(f\"   Equity Gap: {equity_gap:.3f} ({equity_gap/geo_fairness_df['eligibility_rate'].mean()*100:.1f}% of mean)\")\n",
        "        \n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No geographic fairness data found.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Geographic equity analysis error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"üìä FAIRNESS AUDIT SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n‚úÖ Fairness audit completed\")\n",
        "print(\"\\nüí° Recommendations:\")\n",
        "print(\"1. Monitor demographic parity metrics regularly\")\n",
        "print(\"2. Investigate schemes with significant demographic bias\")\n",
        "print(\"3. Review rule engine criteria for potential discriminatory patterns\")\n",
        "print(\"4. Consider ML model retraining with fairness constraints if bias detected\")\n",
        "print(\"5. Implement geographic equity adjustments if needed\")\n",
        "print(\"\\nüîç Next Steps:\")\n",
        "print(\"- Set up automated fairness monitoring\")\n",
        "print(\"- Review rule expressions for potential bias\")\n",
        "print(\"- Consider fairness-aware ML model training\")\n",
        "print(\"- Document fairness metrics in MLflow experiments\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Close database connection\n",
        "db.disconnect()\n",
        "print(\"‚úÖ Database connection closed\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
