{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Auto Identification of Beneficiaries - Data Exploration\n",
        "\n",
        "**Use Case:** AI-PLATFORM-03 - Auto Identification of Beneficiaries  \n",
        "**Objective:** Explore eligibility rules, scheme distributions, candidate lists, and ML scoring patterns  \n",
        "**MLflow Experiment:** `smart/identification_beneficiary/*`\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook explores:\n",
        "- Scheme eligibility rules distribution\n",
        "- Candidate lists and eligibility snapshots\n",
        "- Rule engine vs ML scorer comparisons\n",
        "- Scheme-wise eligibility patterns\n",
        "- Geographic distribution of candidates\n",
        "- Hybrid evaluator performance\n",
        "- Prioritization patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yaml\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add paths\n",
        "project_root = Path().absolute().parent.parent.parent.parent\n",
        "sys.path.append(str(project_root / 'shared' / 'utils'))\n",
        "from db_connector import DBConnector\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 7)\n",
        "\n",
        "# Load config\n",
        "config_path = Path().absolute().parent.parent / \"config\" / \"db_config.yaml\"\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Connect to database\n",
        "db = DBConnector(\n",
        "    host=config['database']['host'],\n",
        "    port=config['database']['port'],\n",
        "    database=config['database']['name'],\n",
        "    user=config['database']['user'],\n",
        "    password=config['database']['password']\n",
        ")\n",
        "db.connect()\n",
        "\n",
        "print(\"‚úÖ Connected to database\")\n",
        "print(f\"   Database: {config['database']['name']} at {config['database']['host']}:{config['database']['port']}\")\n",
        "print(f\"   Schema: {config['database']['schema']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Scheme & Rules Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get schemes with auto-identification enabled\n",
        "schemes_query = \"\"\"\n",
        "SELECT \n",
        "    scheme_code,\n",
        "    scheme_name,\n",
        "    scheme_type,\n",
        "    is_auto_id_enabled,\n",
        "    CASE \n",
        "        WHEN scheme_type = 'CASH' THEN 'Cash Transfer'\n",
        "        WHEN scheme_type = 'NON_CASH' THEN 'Non-Cash Benefit'\n",
        "        ELSE 'Other'\n",
        "    END as scheme_category\n",
        "FROM public.scheme_master\n",
        "WHERE is_auto_id_enabled = true\n",
        "ORDER BY scheme_code\n",
        "\"\"\"\n",
        "\n",
        "schemes_df = pd.read_sql(schemes_query, db.connection)\n",
        "print(f\"üìä Total Schemes with Auto-ID Enabled: {len(schemes_df)}\")\n",
        "print(f\"\\nScheme Categories:\")\n",
        "print(schemes_df['scheme_category'].value_counts())\n",
        "print(f\"\\nFirst 10 Schemes:\")\n",
        "print(schemes_df.head(10).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get eligibility rules summary\n",
        "rules_query = \"\"\"\n",
        "SELECT \n",
        "    scheme_code,\n",
        "    COUNT(*) as rule_count,\n",
        "    COUNT(*) FILTER (WHERE is_mandatory = true) as mandatory_rules,\n",
        "    COUNT(*) FILTER (WHERE rule_type = 'AGE') as age_rules,\n",
        "    COUNT(*) FILTER (WHERE rule_type = 'INCOME') as income_rules,\n",
        "    COUNT(*) FILTER (WHERE rule_type = 'GEOGRAPHY') as geography_rules,\n",
        "    COUNT(*) FILTER (WHERE rule_type = 'CATEGORY') as category_rules,\n",
        "    MAX(priority) as max_priority,\n",
        "    MIN(priority) as min_priority\n",
        "FROM eligibility.scheme_eligibility_rules\n",
        "WHERE (effective_to IS NULL OR effective_to >= CURRENT_DATE)\n",
        "    AND (effective_from <= CURRENT_DATE)\n",
        "GROUP BY scheme_code\n",
        "ORDER BY rule_count DESC\n",
        "\"\"\"\n",
        "\n",
        "rules_summary = pd.read_sql(rules_query, db.connection)\n",
        "print(f\"üìã Rules Summary (Top 15 Schemes):\")\n",
        "print(rules_summary.head(15).to_string(index=False))\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Rule count distribution\n",
        "axes[0, 0].hist(rules_summary['rule_count'], bins=20, edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].set_title('Distribution of Rules per Scheme')\n",
        "axes[0, 0].set_xlabel('Number of Rules')\n",
        "axes[0, 0].set_ylabel('Number of Schemes')\n",
        "\n",
        "# Mandatory vs Optional rules\n",
        "top_schemes = rules_summary.head(10)\n",
        "x = np.arange(len(top_schemes))\n",
        "width = 0.35\n",
        "axes[0, 1].bar(x - width/2, top_schemes['mandatory_rules'], width, label='Mandatory', alpha=0.8)\n",
        "axes[0, 1].bar(x + width/2, top_schemes['rule_count'] - top_schemes['mandatory_rules'], \n",
        "               width, label='Optional', alpha=0.8)\n",
        "axes[0, 1].set_title('Mandatory vs Optional Rules (Top 10 Schemes)')\n",
        "axes[0, 1].set_xlabel('Scheme')\n",
        "axes[0, 1].set_ylabel('Number of Rules')\n",
        "axes[0, 1].set_xticks(x)\n",
        "axes[0, 1].set_xticklabels(top_schemes['scheme_code'], rotation=45, ha='right')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# Rule types distribution\n",
        "rule_types = rules_summary[['age_rules', 'income_rules', 'geography_rules', 'category_rules']].sum()\n",
        "axes[1, 0].pie(rule_types.values, labels=rule_types.index, autopct='%1.1f%%', startangle=90)\n",
        "axes[1, 0].set_title('Rule Types Distribution Across All Schemes')\n",
        "\n",
        "# Priority distribution\n",
        "axes[1, 1].scatter(rules_summary['rule_count'], rules_summary['max_priority'], \n",
        "                   alpha=0.6, s=100)\n",
        "axes[1, 1].set_title('Max Priority vs Number of Rules')\n",
        "axes[1, 1].set_xlabel('Number of Rules')\n",
        "axes[1, 1].set_ylabel('Maximum Priority')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "20 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if eligibility_snapshots table exists and has data\n",
        "try:\n",
        "    snapshots_query = \"\"\"\n",
        "    SELECT \n",
        "        snapshot_id,\n",
        "        snapshot_date,\n",
        "        scheme_code,\n",
        "        COUNT(*) FILTER (WHERE rule_status = 'ELIGIBLE') as rule_eligible,\n",
        "        COUNT(*) FILTER (WHERE rule_status = 'NOT_ELIGIBLE') as rule_not_eligible,\n",
        "        COUNT(*) FILTER (WHERE rule_status = 'POSSIBLE_ELIGIBLE') as rule_possible,\n",
        "        AVG(ml_score) as avg_ml_score,\n",
        "        AVG(hybrid_score) as avg_hybrid_score,\n",
        "        COUNT(*) as total_candidates\n",
        "    FROM eligibility.eligibility_snapshots\n",
        "    GROUP BY snapshot_id, snapshot_date, scheme_code\n",
        "    ORDER BY snapshot_date DESC\n",
        "    LIMIT 100\n",
        "    \"\"\"\n",
        "    snapshots_df = pd.read_sql(snapshots_query, db.connection)\n",
        "    \n",
        "    if len(snapshots_df) > 0:\n",
        "        print(f\"üì∏ Found {len(snapshots_df)} snapshot records\")\n",
        "        print(\"\\nSnapshot Summary:\")\n",
        "        print(snapshots_df.describe())\n",
        "        \n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        \n",
        "        # Eligibility status distribution\n",
        "        status_counts = snapshots_df[['rule_eligible', 'rule_not_eligible', 'rule_possible']].sum()\n",
        "        axes[0, 0].bar(status_counts.index, status_counts.values, color=['green', 'red', 'orange'], alpha=0.7)\n",
        "        axes[0, 0].set_title('Overall Eligibility Status Distribution')\n",
        "        axes[0, 0].set_ylabel('Count')\n",
        "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # ML Score vs Hybrid Score\n",
        "        if snapshots_df['avg_ml_score'].notna().sum() > 0:\n",
        "            axes[0, 1].scatter(snapshots_df['avg_ml_score'], snapshots_df['avg_hybrid_score'], \n",
        "                             alpha=0.6, s=50)\n",
        "            axes[0, 1].plot([0, 1], [0, 1], 'r--', alpha=0.5)\n",
        "            axes[0, 1].set_title('ML Score vs Hybrid Score')\n",
        "            axes[0, 1].set_xlabel('Average ML Score')\n",
        "            axes[0, 1].set_ylabel('Average Hybrid Score')\n",
        "        \n",
        "        # Candidates per scheme\n",
        "        scheme_counts = snapshots_df.groupby('scheme_code')['total_candidates'].sum().sort_values(ascending=False).head(10)\n",
        "        axes[1, 0].barh(range(len(scheme_counts)), scheme_counts.values, alpha=0.7)\n",
        "        axes[1, 0].set_yticks(range(len(scheme_counts)))\n",
        "        axes[1, 0].set_yticklabels(scheme_counts.index)\n",
        "        axes[1, 0].set_title('Top 10 Schemes by Total Candidates')\n",
        "        axes[1, 0].set_xlabel('Total Candidates')\n",
        "        \n",
        "        # Timeline of snapshots\n",
        "        if snapshots_df['snapshot_date'].notna().sum() > 0:\n",
        "            timeline = snapshots_df.groupby(snapshots_df['snapshot_date'].dt.date)['total_candidates'].sum()\n",
        "            axes[1, 1].plot(timeline.index, timeline.values, marker='o', alpha=0.7)\n",
        "            axes[1, 1].set_title('Candidates Over Time')\n",
        "            axes[1, 1].set_xlabel('Date')\n",
        "            axes[1, 1].set_ylabel('Total Candidates')\n",
        "            axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No snapshot data found. This is expected if no evaluations have been run yet.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Eligibility snapshots table may not exist or have no data: {e}\")\n",
        "    print(\"   This is expected if no evaluations have been run yet.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check candidate lists\n",
        "try:\n",
        "    candidates_query = \"\"\"\n",
        "    SELECT \n",
        "        list_id,\n",
        "        list_name,\n",
        "        scheme_code,\n",
        "        list_type,\n",
        "        priority_cutoff,\n",
        "        total_candidates,\n",
        "        created_at\n",
        "    FROM eligibility.candidate_lists\n",
        "    ORDER BY created_at DESC\n",
        "    LIMIT 50\n",
        "    \"\"\"\n",
        "    candidates_df = pd.read_sql(candidates_query, db.connection)\n",
        "    \n",
        "    if len(candidates_df) > 0:\n",
        "        print(f\"üìã Found {len(candidates_df)} candidate lists\")\n",
        "        print(\"\\nCandidate Lists Summary:\")\n",
        "        print(candidates_df.describe(include='all'))\n",
        "        \n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        \n",
        "        # List type distribution\n",
        "        list_types = candidates_df['list_type'].value_counts()\n",
        "        axes[0, 0].pie(list_types.values, labels=list_types.index, autopct='%1.1f%%', startangle=90)\n",
        "        axes[0, 0].set_title('Candidate List Types Distribution')\n",
        "        \n",
        "        # Candidates per scheme\n",
        "        scheme_candidates = candidates_df.groupby('scheme_code')['total_candidates'].sum().sort_values(ascending=False).head(10)\n",
        "        axes[0, 1].barh(range(len(scheme_candidates)), scheme_candidates.values, alpha=0.7)\n",
        "        axes[0, 1].set_yticks(range(len(scheme_candidates)))\n",
        "        axes[0, 1].set_yticklabels(scheme_candidates.index)\n",
        "        axes[0, 1].set_title('Top 10 Schemes by Total Candidates in Lists')\n",
        "        axes[0, 1].set_xlabel('Total Candidates')\n",
        "        \n",
        "        # Priority cutoff distribution\n",
        "        if candidates_df['priority_cutoff'].notna().sum() > 0:\n",
        "            axes[1, 0].hist(candidates_df['priority_cutoff'].dropna(), bins=20, edgecolor='black', alpha=0.7)\n",
        "            axes[1, 0].set_title('Priority Cutoff Distribution')\n",
        "            axes[1, 0].set_xlabel('Priority Cutoff')\n",
        "            axes[1, 0].set_ylabel('Frequency')\n",
        "        \n",
        "        # Lists over time\n",
        "        if candidates_df['created_at'].notna().sum() > 0:\n",
        "            timeline = candidates_df.groupby(candidates_df['created_at'].dt.date)['total_candidates'].sum()\n",
        "            axes[1, 1].plot(timeline.index, timeline.values, marker='o', alpha=0.7)\n",
        "            axes[1, 1].set_title('Candidate Lists Creation Over Time')\n",
        "            axes[1, 1].set_xlabel('Date')\n",
        "            axes[1, 1].set_ylabel('Total Candidates')\n",
        "            axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No candidate lists found. This is expected if no evaluations have been run yet.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Candidate lists table may not exist or have no data: {e}\")\n",
        "    print(\"   This is expected if no evaluations have been run yet.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Rule Engine vs ML Scorer Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare rule engine and ML scorer outputs\n",
        "try:\n",
        "    comparison_query = \"\"\"\n",
        "    SELECT \n",
        "        scheme_code,\n",
        "        rule_status,\n",
        "        COUNT(*) as count,\n",
        "        AVG(ml_score) as avg_ml_score,\n",
        "        AVG(hybrid_score) as avg_hybrid_score,\n",
        "        STDDEV(ml_score) as std_ml_score,\n",
        "        STDDEV(hybrid_score) as std_hybrid_score\n",
        "    FROM eligibility.eligibility_snapshots\n",
        "    WHERE ml_score IS NOT NULL\n",
        "    GROUP BY scheme_code, rule_status\n",
        "    ORDER BY scheme_code, rule_status\n",
        "    \"\"\"\n",
        "    comparison_df = pd.read_sql(comparison_query, db.connection)\n",
        "    \n",
        "    if len(comparison_df) > 0:\n",
        "        print(\"üìä Rule Engine vs ML Scorer Comparison:\")\n",
        "        print(comparison_df.head(20).to_string(index=False))\n",
        "        \n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        \n",
        "        # Rule status distribution\n",
        "        status_dist = comparison_df.groupby('rule_status')['count'].sum()\n",
        "        axes[0, 0].bar(status_dist.index, status_dist.values, \n",
        "                      color=['green', 'red', 'orange'], alpha=0.7)\n",
        "        axes[0, 0].set_title('Rule Engine Status Distribution')\n",
        "        axes[0, 0].set_ylabel('Count')\n",
        "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # ML scores by rule status\n",
        "        for status in comparison_df['rule_status'].unique():\n",
        "            subset = comparison_df[comparison_df['rule_status'] == status]\n",
        "            if len(subset) > 0:\n",
        "                axes[0, 1].bar(subset['scheme_code'].head(10), subset['avg_ml_score'].head(10), \n",
        "                              label=status, alpha=0.7)\n",
        "        axes[0, 1].set_title('Average ML Score by Rule Status (Top 10 Schemes)')\n",
        "        axes[0, 1].set_xlabel('Scheme Code')\n",
        "        axes[0, 1].set_ylabel('Average ML Score')\n",
        "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "        axes[0, 1].legend()\n",
        "        \n",
        "        # Hybrid scores by rule status\n",
        "        for status in comparison_df['rule_status'].unique():\n",
        "            subset = comparison_df[comparison_df['rule_status'] == status]\n",
        "            if len(subset) > 0:\n",
        "                axes[1, 0].bar(subset['scheme_code'].head(10), subset['avg_hybrid_score'].head(10), \n",
        "                              label=status, alpha=0.7)\n",
        "        axes[1, 0].set_title('Average Hybrid Score by Rule Status (Top 10 Schemes)')\n",
        "        axes[1, 0].set_xlabel('Scheme Code')\n",
        "        axes[1, 0].set_ylabel('Average Hybrid Score')\n",
        "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "        axes[1, 0].legend()\n",
        "        \n",
        "        # Score comparison\n",
        "        eligible = comparison_df[comparison_df['rule_status'] == 'ELIGIBLE']\n",
        "        if len(eligible) > 0:\n",
        "            axes[1, 1].scatter(eligible['avg_ml_score'], eligible['avg_hybrid_score'], \n",
        "                             alpha=0.6, s=100, label='ELIGIBLE')\n",
        "        not_eligible = comparison_df[comparison_df['rule_status'] == 'NOT_ELIGIBLE']\n",
        "        if len(not_eligible) > 0:\n",
        "            axes[1, 1].scatter(not_eligible['avg_ml_score'], not_eligible['avg_hybrid_score'], \n",
        "                             alpha=0.6, s=100, label='NOT_ELIGIBLE', color='red')\n",
        "        axes[1, 1].plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
        "        axes[1, 1].set_title('ML Score vs Hybrid Score by Rule Status')\n",
        "        axes[1, 1].set_xlabel('Average ML Score')\n",
        "        axes[1, 1].set_ylabel('Average Hybrid Score')\n",
        "        axes[1, 1].legend()\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No comparison data found. This is expected if no evaluations have been run yet.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Comparison data may not be available: {e}\")\n",
        "    print(\"   This is expected if no evaluations have been run yet.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze geographic distribution (if available in snapshots)\n",
        "try:\n",
        "    geo_query = \"\"\"\n",
        "    SELECT \n",
        "        district_id,\n",
        "        block_id,\n",
        "        COUNT(*) as candidate_count,\n",
        "        AVG(hybrid_score) as avg_score,\n",
        "        COUNT(*) FILTER (WHERE rule_status = 'ELIGIBLE') as eligible_count\n",
        "    FROM eligibility.eligibility_snapshots\n",
        "    WHERE district_id IS NOT NULL\n",
        "    GROUP BY district_id, block_id\n",
        "    ORDER BY candidate_count DESC\n",
        "    LIMIT 50\n",
        "    \"\"\"\n",
        "    geo_df = pd.read_sql(geo_query, db.connection)\n",
        "    \n",
        "    if len(geo_df) > 0:\n",
        "        print(\"üó∫Ô∏è Geographic Distribution:\")\n",
        "        print(geo_df.head(20).to_string(index=False))\n",
        "        \n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        \n",
        "        # Top districts by candidates\n",
        "        district_counts = geo_df.groupby('district_id')['candidate_count'].sum().sort_values(ascending=False).head(10)\n",
        "        axes[0, 0].barh(range(len(district_counts)), district_counts.values, alpha=0.7)\n",
        "        axes[0, 0].set_yticks(range(len(district_counts)))\n",
        "        axes[0, 0].set_yticklabels(district_counts.index)\n",
        "        axes[0, 0].set_title('Top 10 Districts by Candidate Count')\n",
        "        axes[0, 0].set_xlabel('Candidate Count')\n",
        "        \n",
        "        # Average score by district\n",
        "        district_scores = geo_df.groupby('district_id')['avg_score'].mean().sort_values(ascending=False).head(10)\n",
        "        axes[0, 1].barh(range(len(district_scores)), district_scores.values, alpha=0.7, color='green')\n",
        "        axes[0, 1].set_yticks(range(len(district_scores)))\n",
        "        axes[0, 1].set_yticklabels(district_scores.index)\n",
        "        axes[0, 1].set_title('Top 10 Districts by Average Score')\n",
        "        axes[0, 1].set_xlabel('Average Score')\n",
        "        \n",
        "        # Eligibility rate by district\n",
        "        district_eligibility = geo_df.groupby('district_id').agg({\n",
        "            'candidate_count': 'sum',\n",
        "            'eligible_count': 'sum'\n",
        "        })\n",
        "        district_eligibility['eligibility_rate'] = district_eligibility['eligible_count'] / district_eligibility['candidate_count']\n",
        "        top_eligibility = district_eligibility.nlargest(10, 'eligibility_rate')\n",
        "        axes[1, 0].barh(range(len(top_eligibility)), top_eligibility['eligibility_rate'].values, \n",
        "                       alpha=0.7, color='orange')\n",
        "        axes[1, 0].set_yticks(range(len(top_eligibility)))\n",
        "        axes[1, 0].set_yticklabels(top_eligibility.index)\n",
        "        axes[1, 0].set_title('Top 10 Districts by Eligibility Rate')\n",
        "        axes[1, 0].set_xlabel('Eligibility Rate')\n",
        "        \n",
        "        # Scatter: candidates vs eligibility rate\n",
        "        axes[1, 1].scatter(district_eligibility['candidate_count'], \n",
        "                          district_eligibility['eligibility_rate'], \n",
        "                          alpha=0.6, s=100)\n",
        "        axes[1, 1].set_title('Candidate Count vs Eligibility Rate by District')\n",
        "        axes[1, 1].set_xlabel('Candidate Count')\n",
        "        axes[1, 1].set_ylabel('Eligibility Rate')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No geographic data found. This is expected if no evaluations have been run yet.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Geographic data may not be available: {e}\")\n",
        "    print(\"   This is expected if no evaluations have been run yet.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary & Insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"üìä DATA EXPLORATION SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n‚úÖ Schemes with Auto-ID: {len(schemes_df)}\")\n",
        "print(f\"‚úÖ Total Rules: {rules_summary['rule_count'].sum() if len(rules_summary) > 0 else 0}\")\n",
        "\n",
        "try:\n",
        "    if 'snapshots_df' in locals() and len(snapshots_df) > 0:\n",
        "        print(f\"‚úÖ Eligibility Snapshots: {len(snapshots_df)}\")\n",
        "        print(f\"   - Total Candidates: {snapshots_df['total_candidates'].sum():,.0f}\")\n",
        "        print(f\"   - Average ML Score: {snapshots_df['avg_ml_score'].mean():.3f}\")\n",
        "        print(f\"   - Average Hybrid Score: {snapshots_df['avg_hybrid_score'].mean():.3f}\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è  No snapshot data available\")\n",
        "\n",
        "try:\n",
        "    if 'candidates_df' in locals() and len(candidates_df) > 0:\n",
        "        print(f\"‚úÖ Candidate Lists: {len(candidates_df)}\")\n",
        "        print(f\"   - Total Candidates in Lists: {candidates_df['total_candidates'].sum():,.0f}\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è  No candidate list data available\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° Key Insights:\")\n",
        "print(\"=\"*80)\n",
        "print(\"1. Review rule distributions to identify schemes with complex eligibility criteria\")\n",
        "print(\"2. Compare ML scores with rule engine outputs to validate hybrid evaluator\")\n",
        "print(\"3. Analyze geographic patterns to identify coverage gaps\")\n",
        "print(\"4. Monitor candidate list generation patterns for prioritization insights\")\n",
        "print(\"\\nüîç Next Steps:\")\n",
        "print(\"- Run fairness audit notebook to check for demographic biases\")\n",
        "print(\"- Execute model training if sufficient historical data is available\")\n",
        "print(\"- Review prioritization patterns for optimization opportunities\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Close database connection\n",
        "db.disconnect()\n",
        "print(\"‚úÖ Database connection closed\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
