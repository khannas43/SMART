{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Eligibility Scoring - Data Exploration\n",
        "\n",
        "This notebook explores the schemes table and performs EDA for eligibility scoring.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'shared', 'utils'))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import mlflow\n",
        "import yaml\n",
        "\n",
        "from db_connector import DBConnector\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print('âœ… Libraries imported successfully')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration\n",
        "config_path = '../use-cases/eligibility_scoring/config/db_config.yaml'\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print('âœ… Configuration loaded')\n",
        "print(f\"Database: {config['database']['host']}:{config['database']['port']}/{config['database']['database']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize MLflow\n",
        "mlflow.set_tracking_uri(config['mlflow']['tracking_uri'])\n",
        "mlflow.set_experiment(config['mlflow']['experiment_name'])\n",
        "\n",
        "print(f\"âœ… MLflow tracking: {mlflow.get_tracking_uri()}\")\n",
        "print(f\"âœ… MLflow experiment: {config['mlflow']['experiment_name']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connect to database\n",
        "db = DBConnector(\n",
        "    host=config['database']['host'],\n",
        "    port=config['database']['port'],\n",
        "    database=config['database']['database'],\n",
        "    user=config['database']['user'],\n",
        "    password=config['database']['password']\n",
        ")\n",
        "db.connect()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all tables\n",
        "tables = db.list_tables()\n",
        "print(f\"ðŸ“Š Available tables ({len(tables)}):\")\n",
        "for table in tables:\n",
        "    print(f\"  - {table}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get schemes table info\n",
        "schemes_info = db.get_table_info('schemes')\n",
        "print(\"ðŸ“‹ Schemes Table Schema:\")\n",
        "print(schemes_info.to_string())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get row count\n",
        "row_count = db.get_table_count('schemes')\n",
        "print(f\"ðŸ“Š Total rows in schemes table: {row_count:,}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load schemes data\n",
        "query = \"SELECT * FROM schemes LIMIT 10000\"  # Adjust limit as needed\n",
        "df_schemes = db.execute_query(query)\n",
        "\n",
        "print(f\"âœ… Loaded {len(df_schemes):,} rows\")\n",
        "print(f\"âœ… Columns: {list(df_schemes.columns)}\")\n",
        "df_schemes.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "print(\"ðŸ“Š Dataset Shape:\")\n",
        "print(f\"Rows: {df_schemes.shape[0]:,}\")\n",
        "print(f\"Columns: {df_schemes.shape[1]}\")\n",
        "print(\"\\nðŸ“‹ Data Types:\")\n",
        "print(df_schemes.dtypes)\n",
        "print(\"\\nðŸ“Š Missing Values:\")\n",
        "missing = df_schemes.isnull().sum()\n",
        "print(missing[missing > 0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Numerical columns summary\n",
        "numerical_cols = df_schemes.select_dtypes(include=[np.number]).columns\n",
        "if len(numerical_cols) > 0:\n",
        "    print(\"ðŸ“Š Numerical Columns Summary:\")\n",
        "    print(df_schemes[numerical_cols].describe())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorical columns\n",
        "categorical_cols = df_schemes.select_dtypes(include=['object']).columns\n",
        "if len(categorical_cols) > 0:\n",
        "    print(\"ðŸ“Š Categorical Columns:\")\n",
        "    for col in categorical_cols[:10]:  # First 10\n",
        "        print(f\"\\n{col}:\")\n",
        "        print(df_schemes[col].value_counts().head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start MLflow run\n",
        "with mlflow.start_run(run_name=\"data_exploration_v1\") as run:\n",
        "    # Log dataset info\n",
        "    mlflow.log_param(\"dataset\", \"schemes\")\n",
        "    mlflow.log_param(\"rows\", len(df_schemes))\n",
        "    mlflow.log_param(\"columns\", df_schemes.shape[1])\n",
        "    mlflow.log_param(\"missing_values\", df_schemes.isnull().sum().sum())\n",
        "    \n",
        "    # Log numerical statistics\n",
        "    if len(numerical_cols) > 0:\n",
        "        for col in numerical_cols:\n",
        "            mlflow.log_metric(f\"{col}_mean\", float(df_schemes[col].mean()))\n",
        "            mlflow.log_metric(f\"{col}_std\", float(df_schemes[col].std()))\n",
        "    \n",
        "    print(f\"âœ… Logged to MLflow run: {run.info.run_id}\")\n",
        "    print(f\"ðŸ“Š View at: {mlflow.get_tracking_uri()}/#/experiments/{run.info.experiment_id}/runs/{run.info.run_id}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save processed data\n",
        "output_dir = config['data']['output_path']\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "df_schemes.to_csv(f\"{output_dir}schemes_sample.csv\", index=False)\n",
        "print(f\"âœ… Data saved to {output_dir}schemes_sample.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Close database connection\n",
        "db.disconnect()\n",
        "print(\"âœ… Database connection closed\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
